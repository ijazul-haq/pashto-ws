{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "176a246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textwrap, joblib, random\n",
    "from sklearn_crfsuite import CRF, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0711aba",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "471d9fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  3000\n",
      "Train:  2400\n",
      "Test:  600\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/sample.csv', header=None)\n",
    "df = df.loc[:,0]\n",
    "tagged_sentences = []\n",
    "for sent in df:\n",
    "    sent = sent.strip(' B').split('B')\n",
    "    tagged_sent = []\n",
    "    for word in sent:\n",
    "        word = word.split('S')\n",
    "        for i, w in enumerate(word):\n",
    "            if(i+1 < len(word)): el = (w,'S')\n",
    "            else: el = (w,'B')\n",
    "            tagged_sent.append(el)\n",
    "    tagged_sentences.append(tagged_sent)\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(tagged_sentences)    \n",
    "cutoff = int(.8 * len(tagged_sentences))\n",
    "train = tagged_sentences[:cutoff]\n",
    "test = tagged_sentences[cutoff:]\n",
    "\n",
    "print('Total: ', len(tagged_sentences))\n",
    "print('Train: ', len(train))\n",
    "print('Test: ', len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3f40e7",
   "metadata": {},
   "source": [
    "# Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56e14e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(sentence, index):\n",
    "    token = sentence[index]\n",
    "    prev_1 = ''.join(sentence[index-1:index+1])\n",
    "    next_1 = ''.join(sentence[index+1:index+2])\n",
    "    \n",
    "    features = {\n",
    "        'token': token,\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'length': len(token),\n",
    "        'is_numeric': token.isdigit(),\n",
    "        'pfx_1': token[0] if(len(token) > 2) else '',\n",
    "        'pfx_2': token[:2] if(len(token) > 3) else '',\n",
    "        'pfx_3': token[:3] if(len(token) > 4) else '',\n",
    "        'sfx_1': token[-1] if(len(token) > 2) else '',\n",
    "        'sfx_2': token[-2:] if(len(token) > 3) else '',\n",
    "        'sfx_3': token[-3:] if(len(token) > 4) else '',\n",
    "        \n",
    "        'prev_1': prev_1,\n",
    "        'prev_1_len': len(prev_1),\n",
    "        'prev_1_pfx_1': '' if (not prev_1 or len(prev_1)<3) else prev_1[0],\n",
    "        'prev_1_pfx_2': '' if (not prev_1 or len(prev_1)<4) else prev_1[:2],\n",
    "        'prev_1_sfx_1': '' if (not prev_1 or len(prev_1)<3) else prev_1[-1],\n",
    "        'prev_1_sfx_2': '' if (not prev_1 or len(prev_1)<4) else prev_1[-2:],\n",
    "        'prev_2': '' if(index<2) else ''.join(sentence[index-2:index-1]),\n",
    "        \n",
    "        'next_1': next_1,\n",
    "        'next_1_len': len(next_1),\n",
    "        'next_1_pfx_1': '' if (not next_1 or len(next_1)<3) else next_1[0],       \n",
    "        'next_1_pfx_2': '' if (not next_1 or len(next_1)<4) else next_1[:2],       \n",
    "        'next_1_sfx_1': '' if (not next_1 or len(next_1)<3) else next_1[-1],       \n",
    "        'next_1_sfx_2': '' if (not next_1 or len(next_1)<4) else next_1[-2:],       \n",
    "        'next_2': ''.join(sentence[index+2:index+3])\n",
    "      }\n",
    "    return features\n",
    "\n",
    "def transform_to_dataset(tagged_sentences):\n",
    "    X, y = [], []\n",
    "    for tagged in tagged_sentences:\n",
    "        untagged = [first for first, second in tagged]\n",
    "        X.append([features(untagged, index) for index in range(len(untagged))])\n",
    "        y.append([tag for _, tag in tagged])\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = transform_to_dataset(train)\n",
    "X_test, y_test = transform_to_dataset(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c09e436",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c743cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/segmenter.sav']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "model.fit(X_train, y_train)\n",
    "joblib.dump(model, 'models/segmenter.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2388d09d",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "247670a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " P\t R\t Acc\t F1\n",
      "95.55\t93.77\t98.69\t94.64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "prec = round(metrics.flat_precision_score(y_test, y_pred, average='macro')*100, 2)\n",
    "rec = round(metrics.flat_recall_score(y_test, y_pred, average='macro')*100, 2)\n",
    "f1 = round(metrics.flat_f1_score(y_test, y_pred, average='macro')*100, 2)\n",
    "acc = round(metrics.flat_accuracy_score(y_test, y_pred)*100, 2)\n",
    "\n",
    "print(' P\\t R\\t Acc\\t F1')\n",
    "row = f'{prec}\\t{rec}\\t{acc}\\t{f1}\\n'\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425a3b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
